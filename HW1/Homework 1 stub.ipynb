{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ad6b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "import gzip\n",
    "import dateutil.parser\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e6a1e4d-c80f-4030-8770-1d719320bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}\n",
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6885040-d9f2-461a-a2c8-ba31f83eafaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 1\n",
    "f = gzip.open(\"fantasy_10000.json.gz\")\n",
    "dataset = []\n",
    "for l in f:\n",
    "    dataset.append(json.loads(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1ebbbb2-d5ae-405e-a02d-7307265387b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [len(d['review_text']) for d in dataset]\n",
    "Y = [d['rating'] for d in dataset]\n",
    "max_length = max(X)\n",
    "X_scaled = [x / max_length for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb042f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = np.array(X_scaled).reshape(-1, 1)\n",
    "Y = np.array(Y)\n",
    "model = LinearRegression().fit(X_scaled, Y)\n",
    "predictions = model.predict(X_scaled)\n",
    "MSE = mean_squared_error(Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aff0ac61-0957-4d3d-ba0b-2db2b222026d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1': [3.685681355016952, 0.9833539181066135, 1.5522086622355378]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q1'] = [model.intercept_, model.coef_[0], MSE]\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d6a1c2a-c1cf-4b17-bd42-687499297c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q1'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6331a843-78ac-4764-bf37-5dd234f09229",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 2\n",
    "for d in dataset:\n",
    "    t = dateutil.parser.parse(d['date_added'])\n",
    "    d['parsed_date'] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abce94cf-a7ca-4eef-b5fa-920349ee1003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    t = datum['parsed_date']\n",
    "    weekday = [0] * 6\n",
    "    month = [0] * 11\n",
    "    if t.weekday() != 0:\n",
    "        weekday[t.weekday()-1] = 1\n",
    "    if t.month != 1:\n",
    "        month[t.month - 2] = 1\n",
    "    return [1] + [len(datum['review_text'])/max_length] + weekday + month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18be1bc1-7cc0-4249-9b0c-513c37b86665",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = [feature(d) for d in dataset]\n",
    "Y2 = [d['rating'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee825436",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q2'] = [X2[0], X2[1]]\n",
    "assertFloatList(answers['Q2'][0], 19)\n",
    "assertFloatList(answers['Q2'][1], 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f566081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.array(X2).reshape(-1, 19)\n",
    "Y2 = np.array(Y2)\n",
    "model2 = LinearRegression().fit(X2, Y2)\n",
    "predictions2 = model2.predict(X2)\n",
    "mse2 = mean_squared_error(Y2, predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35d18540-6413-4459-8082-0f8cc1d3e276",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "939c02d3-eb26-4e65-96a2-d55fc41d2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature3(datum):\n",
    "    t = datum['parsed_date']\n",
    "    return [1] + [len(datum['review_text'])/max_length] + [t.weekday()] + [t.month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3efaacd2-6ac8-4a3c-8d32-60ad8f389917",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = [feature3(d) for d in dataset]\n",
    "Y3 = [d['rating'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "595220ef-b8b2-4377-9e2c-1743495b9c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = np.array(X3).reshape(-1, 4)\n",
    "Y3 = np.array(Y3)\n",
    "model3 = LinearRegression().fit(X3, Y3)\n",
    "predictions3 = model3.predict(X3)\n",
    "mse3 = mean_squared_error(Y3, predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d2e124d-10d4-4147-a2d3-172c50f47029",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3'] = [mse2, mse3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "289b8ec1-53bd-4796-9613-b3557fffd84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q3'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d89e772-b1ad-46fc-aeb8-45a6df15fa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54ab0a2f-9efa-4035-96ba-dbce8c86f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1029574-b4c4-4675-83ad-c20674a2428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = [feature(d) for d in dataset]\n",
    "X3 = [feature3(d) for d in dataset]\n",
    "Y = [d['rating'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d289580-a10d-48a5-85ae-2d3e77b007d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2, test2 = X2[:len(X2)//2], X2[len(X2)//2:]\n",
    "train3, test3 = X3[:len(X3)//2], X3[len(X3)//2:]\n",
    "trainY, testY = Y[:len(Y)//2], Y[len(Y)//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c0c46b5-774b-44b9-856b-dd1d4ab62e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = np.array(train2).reshape(-1, 19)\n",
    "train3 = np.array(train3).reshape(-1, 4)\n",
    "trainY = np.array(trainY)\n",
    "modeltrain2 = LinearRegression().fit(train2, trainY)\n",
    "modeltrain3 = LinearRegression().fit(train3, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "276ad6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictiontext2 = modeltrain2.predict(test2)\n",
    "predictiontext3 = modeltrain3.predict(test3)\n",
    "test_mse2 = mean_squared_error(testY, predictiontext2)\n",
    "test_mse3 = mean_squared_error(testY, predictiontext3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cfc160b-eab4-406d-8ff3-e9e1670bbbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q4'] = [test_mse2, test_mse3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "453c7ca7-8649-4722-9d6a-1980b536e7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q4'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a38cc78-c502-4ad1-b2db-d8358c0caa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7dde2008-33d7-4fa9-8303-ea639bf54203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'review/appearance': 2.5,\n",
       "  'beer/style': 'Hefeweizen',\n",
       "  'review/palate': 1.5,\n",
       "  'review/taste': 1.5,\n",
       "  'beer/name': 'Sausa Weizen',\n",
       "  'review/timeUnix': 1234817823,\n",
       "  'beer/ABV': 5.0,\n",
       "  'beer/beerId': '47986',\n",
       "  'beer/brewerId': '10325',\n",
       "  'review/timeStruct': {'isdst': 0,\n",
       "   'mday': 16,\n",
       "   'hour': 20,\n",
       "   'min': 57,\n",
       "   'sec': 3,\n",
       "   'mon': 2,\n",
       "   'year': 2009,\n",
       "   'yday': 47,\n",
       "   'wday': 0},\n",
       "  'review/overall': 1.5,\n",
       "  'review/text': 'A lot of foam. But a lot.\\tIn the smell some banana, and then lactic and tart. Not a good start.\\tQuite dark orange in color, with a lively carbonation (now visible, under the foam).\\tAgain tending to lactic sourness.\\tSame for the taste. With some yeast and banana.',\n",
       "  'user/profileName': 'stcules',\n",
       "  'review/aroma': 2.0}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"beer_50000.json\")\n",
    "dataset = []\n",
    "for l in f:\n",
    "    dataset.append(eval(l))\n",
    "dataset[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cabb75ec-826a-497e-b158-f5c340aea4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[len(d['review/text'])] for d in dataset]\n",
    "y = [1 if d['review/overall'] >= 4 else 0 for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "befbbb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(class_weight='balanced')\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "67866d15-cd7a-4643-87a6-d20fa7135428",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e3b8297c-444e-4832-8f75-fae48d074162",
   "metadata": {},
   "outputs": [],
   "source": [
    "BER = 0.5 * (FP / (TN + FP) + FN / (TP + FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4cf3f97-14ee-4c2b-a1b0-e5df323bfc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14201, 10503, 5885, 19411, 0.46830315259572763]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q5'] = [TP, TN, FP, FN, BER]\n",
    "answers['Q5'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb92ee88-4f3c-44fc-a9c0-57e377f9c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q5'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2a71178c-589e-433c-8bdb-70c5e1510fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 6\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "93cdb65b-4cd4-47f1-a4f6-50f0b68a6fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "precs = []\n",
    "y_scores = clf.predict_proba(X)[:, 1] \n",
    "def precision_at_k(k):\n",
    "    sorted_indices = np.argsort(y_scores)[::-1]\n",
    "    y_np = np.array(y)\n",
    "    y_pred_np = np.array(y_pred)\n",
    "\n",
    "    top_k_true = y_np[sorted_indices][:k]\n",
    "    top_k_pred = y_pred_np[sorted_indices][:k]\n",
    "    \n",
    "    return precision_score(top_k_true, top_k_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5a936845-ac24-4e7d-b24a-7aa54ab20fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [1,100,1000,10000]:\n",
    "    precs.append(precision_at_k(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2926f098-8166-4748-9ad5-97ece5d67869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.75, 0.71, 0.7146]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q6'] = precs\n",
    "answers['Q6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "934b27e5-eddc-4cd5-9dd5-5d91a17c9f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q6'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e8291f55-cfa1-4979-bcaa-42a238e9a844",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8a9c5fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a0aca9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_encoder = LabelEncoder()\n",
    "styles = [d['beer/style'] for d in dataset]\n",
    "style_encoder.fit(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aa6ab594",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for d in dataset:\n",
    "    text_length = len(d['review/text'])\n",
    "    style_encoded = style_encoder.transform([d.get('beer/style', '')])[0]\n",
    "    abv = d.get('beer/ABV', 0)\n",
    "    appearance = d.get('review/appearance', 0)\n",
    "    palate = d.get('review/palate', 0)\n",
    "    taste = d.get('review/taste', 0)\n",
    "    aroma = d.get('review/aroma', 0)\n",
    "    profile_name_length = len(d.get('user/profileName', ''))\n",
    "    \n",
    "    X.append([text_length, style_encoded, abv, appearance, palate, taste, aroma, profile_name_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7fd3d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6c33863e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09060142, -0.14676425, -0.44167152,  0.20707627,  0.86199164,\n",
       "         1.70322824,  0.31038222, -0.0179636 ]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(X)\n",
    "TN, FP, FN, TP = confusion_matrix(y, y_pred).ravel()\n",
    "BER = 0.5 * (FP / (TN + FP) + FN / (TP + FN))\n",
    "BER\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cef0c655-2a38-4186-887c-355bc5575356",
   "metadata": {},
   "outputs": [],
   "source": [
    "its_test_BER = 0.1750115410564314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8ab81b75-b051-4b2c-bb3e-64fd95cc0b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q7'] = [\"Enhanced the model by incorporating features like the encoded beer style, alcohol by volume (ABV), individual ratings for appearance, palate, taste, and aroma, as well as the length of the user's profile name, in addition to the original review text length.\", its_test_BER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06383de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_hw1.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024a628f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc16d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
